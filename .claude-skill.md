---
name: codex
description: Orchestrate OpenAI Codex CLI agents for parallel task execution
tags: [agents, automation, codex, openai, parallel]
---

# Codex Agent Orchestration Skill

This skill provides convenient access to the Codex MCP for spawning and managing multiple OpenAI Codex CLI agents running in parallel with unattended execution.

## When to Use

Use this skill when:
- You need to delegate multiple coding tasks simultaneously
- You want to leverage OpenAI API tokens (free or paid)
- You need unattended, autonomous code execution
- You want to parallelize testing, refactoring, or code generation
- You need to offload compute-intensive tasks to separate processes

## Authentication Check

The Codex MCP uses your existing codex CLI authentication. Before using any codex tools, verify:

```
Check if codex is available
```

If not authenticated:
```bash
# Authenticate codex CLI
codex login --api-key "your-openai-api-key"
```

## Available Tools

### 1. check_codex_available
Verify codex CLI is installed and working.

**Example:**
```
Check if codex is available
```

### 2. spawn_agent
Spawn a single codex agent for autonomous task execution.

**Parameters:**
- task (required): The task/prompt
- workdir (optional): Working directory
- model (optional): Model to use (default: o3)

**Example:**
```
Spawn a codex agent with task "Fix all TypeScript errors in src/" in /Users/tim/project
```

### 3. spawn_parallel_agents
Spawn multiple agents in parallel.

**Parameters:**
- tasks (required): Array of task configurations

**Example:**
```
Spawn parallel codex agents:
- "Run unit tests" in /Users/tim/project
- "Run integration tests" in /Users/tim/project
- "Generate API docs" in /Users/tim/project
```

### 4. list_agents
List all active and completed agents.

**Parameters:**
- filter (optional): all | running | completed

**Example:**
```
List running codex agents
```

### 5. get_agent_output
Retrieve output from a specific agent.

**Parameters:**
- agent_id (required): The agent ID

**Example:**
```
Get output from agent abc-123-def
```

### 6. wait_for_agent
Wait for an agent to complete.

**Parameters:**
- agent_id (required): The agent ID
- timeout (optional): Timeout in milliseconds

**Example:**
```
Wait for agent abc-123-def to complete
```

### 7. stop_agent
Terminate a running agent.

**Parameters:**
- agent_id (required): The agent ID
- signal (optional): SIGTERM | SIGKILL

**Example:**
```
Stop agent abc-123-def
```

## Common Workflows

### Workflow 1: Single Agent Task

```
1. Spawn a codex agent to "Add unit tests for auth module" in /Users/tim/app
2. Wait for agent <id> to complete
3. Get output from agent <id>
```

### Workflow 2: Parallel Testing

```
1. Spawn parallel codex agents:
   - "Run unit tests" in /Users/tim/app
   - "Run integration tests" in /Users/tim/app
   - "Run e2e tests" in /Users/tim/app
2. List running agents
3. Wait for each agent to complete
4. Collect results from all agents
```

### Workflow 3: Parallel Refactoring

```
1. Spawn parallel codex agents:
   - "Refactor auth service" in /Users/tim/app/backend
   - "Refactor user service" in /Users/tim/app/backend
   - "Update frontend components" in /Users/tim/app/frontend
2. Monitor agents with list_agents
3. Get output from completed agents
```

### Workflow 4: Long-Running Agent Monitoring

```
1. Spawn agent for long task
2. List agents periodically to check status
3. Get partial output with get_agent_output
4. Wait for completion or stop if needed
```

## Best Practices

### Task Design
- **Be specific**: Clear, unambiguous task descriptions
- **Include context**: Mention relevant files, directories, or requirements
- **Set scope**: Define boundaries to prevent over-engineering
- **Provide examples**: Include expected output or test cases

### Resource Management
- **Monitor agents**: Use list_agents regularly to track progress
- **Clean up**: Stop agents that are stuck or no longer needed
- **Parallel wisely**: Don't spawn too many agents (system resources)
- **Set timeouts**: Use wait_for_agent with reasonable timeouts

### Security
- **Isolated environments**: Only use in Docker containers or VMs
- **Version control**: Always have git commits before running agents
- **Backups**: Keep backups of important files
- **Review output**: Always review agent changes before merging

### Error Handling
- **Check output**: Always check agent exit codes and stderr
- **Retry logic**: Resubmit tasks if agents fail unexpectedly
- **Incremental tasks**: Break large tasks into smaller chunks
- **Fallback**: Have a plan if agents fail

## Troubleshooting

### Agent Not Starting
**Symptom:** spawn_agent returns error

**Solutions:**
1. Check codex is installed: `which codex`
2. Verify authentication: `codex login --api-key "key"`
3. Check workdir exists and is writable

### Agent Stuck/Hanging
**Symptom:** Agent runs forever without completing

**Solutions:**
1. Check output: `Get output from agent <id>`
2. Stop agent: `Stop agent <id> with signal SIGKILL`
3. Review task complexity - may need to be broken down

### Authentication Errors
**Symptom:** "OpenAI API authentication failed"

**Solutions:**
1. Re-authenticate codex: `codex login --api-key "your-key"`
2. Verify API key is valid and has quota
3. Check network connectivity

### Output Not Captured
**Symptom:** get_agent_output shows empty stdout/stderr

**Solutions:**
1. Wait longer - agent may still be running
2. Check if agent crashed: `list_agents`
3. Verify task is producing output (not just file modifications)

## Model Selection

Different models for different tasks:

- **o3**: Best for complex reasoning, architecture, refactoring
- **o4-mini**: Faster, cheaper, good for simple tasks
- **gpt-4o**: Balanced performance and cost

**Example:**
```
Spawn agent with task "Quick syntax fixes" using model "o4-mini"
```

## Integration with Other MCPs

Combine Codex agents with other MCPs:

### With Jira/Atlassian
```
1. Get Jira ticket requirements
2. Spawn codex agent to implement feature
3. Update Jira ticket with results
```

### With GitHub
```
1. Spawn parallel agents for different features
2. Collect outputs
3. Create PR using GitHub MCP
```

### With Testing Tools
```
1. Spawn agent to generate tests
2. Run tests with CI/CD tools
3. Report results to Slack/Teams
```

## Safety Reminders

⚠️ **CRITICAL**: This MCP uses `--dangerously-bypass-approvals-and-sandbox`

- All commands execute WITHOUT approval
- File modifications happen without confirmation
- Destructive operations are NOT prevented
- Only use in ISOLATED ENVIRONMENTS

✅ **Safe Usage:**
- Docker containers with limited access
- Dedicated development VMs
- Feature branches with git
- Always review changes before merging

❌ **Unsafe Usage:**
- Production systems
- Shared development machines
- Repositories without version control
- Systems with sensitive data
